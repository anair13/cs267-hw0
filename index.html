<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-57252749-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'UA-57252749-1');
</script>

<link rel="StyleSheet" href="style.css" type="text/css" media="all" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Deep Learning for AI</title>
<style type="text/css">
#primarycontent h1 {
  font-variant: small-caps;
}
#primarycontent h3 {
}
#primarycontent teasertext {
  text-align: center;
}
#primarycontent p {
  text-align: center;
}
#primarycontent {
  text-align: justify;
}
#primarycontent p {
  text-align: justify;
  padding-left: 10px;
  padding-right: 10px;
}
#primarycontent p iframe {
  text-align: center;
}
.featart {
  margin:4px;
}
.hoverdiv {
  background-color:black;
  margin-top:2px;
  margin-bottom:10px;
  width:100%;
}
.hoverdiv:hover {
  background-color:white;
}

iframe {
  margin: auto;
}
</style>

<script type="text/javascript">
  function togglevis(elid){
    el=document.getElementById(elid);
    aelid=elid+"a";
    ael=document.getElementById(aelid);
    if(el.style.display=='none'){
      el.style.display='inline-table';
      ael.innerHTML="[Hide BibTex]";
    }else{
      el.style.display='none';
      ael.innerHTML="[Show BibTex]";
    }
  }
</script>
<script type="text/javascript"
  src="http://www.maths.nottingham.ac.uk/personal/drw/LaTeXMathML.js">
</script>
<!--
<script type="text/javascript" src="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.js"></script>
<link rel="stylesheet" type="text/css" href="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.standardarticle.css" />
-->

</head>
<body>
<div id="primarycontent">
<h1 align="center" itemprop="name"><strong>Parallel Computing for Computer Vision</strong></h1>

<center>
<ul id="people" itemprop="accountablePerson">
	<li><h4>Ashvin Nair</h4></li>
</ul>
</center>

<!-- <img src="img/s6.jpg" itemprop="image" width="800" alt="teaserImage"> -->

<h3>About Me</h3>
<p>I am a first year graduate student in the BAIR group interested in computer vision and reinforcement learning. From this class, first I would like to gain an appreciation of the challenges and possibilities in parallel computing, and get a sense of the large-scale problems people are trying to solve today. Second, I would like practical knowledge about speeding up physical simulations and machine learning algorithms. My research is often blocked by the result of large computational workloads. Specifically, I make extensive use of a robotics simulator, <a href="http://www.mujoco.org/">MuJoCo</a>, and fitting large neural networks including convolutional neural networks or non-standard compute-heavy layers. Both of these can potentially be parallelized, especially on the GPU.
</p>

<h3>CUDA for Image Recognition</h3>
<p>A key problem in computer vision is recognition: given an image, autonomously label the contents of the image. This problem has a long history and until a few years ago, it was still relatively unsolved. The ImageNet competition became a standard benchmark in this community. ImageNet is a public dataset of millions of images each labeled by humans as one of a thousand classes such as "dog", "tank", "cheeseburger", or "volcano". Competition entrants train an image recognition model using this data, and are evaluated on their performance on a held-out set.</p>

<p>While most entries mostly used delicately engineered computer vision pipelines and achieved around 25% error rates similar to previous years, the winning entry from University of Toronto used a large convolutional neural network trained end-to-end on this dataset, obtaining an error rate of around 15%. Even though they used CUDA to train the neural network, the final network, now commonly called AlexNet, still took 5-6 days to train; without parallelization, the training requirements would have been almost impossible at the time. The subsequent impact on image recognition is shown below: since 2012, more and more entries are using GPUs to train their systems and further improving the accuracy dramatically.
</p>
<center><img src="img/imagenet.png" itemprop="image" width="400" alt="teaserImage"></center>
<h3>Computational Challenges</h3>
<p>AlexNet includes about 60 million parameters, many reused by performing convolutions on the input image. To run such a network forward to obtain predictions, a back-of-the-envelope calculation suggests about 500M operations (likely more). Training such a network on a single image also involves a backward pass of roughly the same complexity. The training set used is about 1 million images and the training set is reused about 100 times during training. So in total, successfully training the network once takes about 1e17 operations. For context, the most powerful supercomputer at the time (IBM Sequoia) performed around 1e16 flop/s (peak), and the top commodity CPU was performing than 1e10 flop/s. This means the network would likely take on the order of 100 days to train on a CPU. Furthermore, the usual workflow for improving network performance may involve repeatedly training such a network.
</p>

<p>To solve this problem, AlexNet was instead implemented to run in parallel on a machine with 2 GPUs (=4e11 flop/s) using CUDA. This choice takes advantage of some properties of training neural networks: the computation is mostly simple linear algebra operations and "batch" gradient descent over several points of data is often more stable and lends itself naturally to data parallelism. Assuming the numbers above, this brings optimal training time to around 3 days. This means the parallel implementation was about 50% efficient. Given that the task involves loading large amounts of data (the training data is about 50GB) and many of the subroutines (such as convolution on the GPU) were self-defined and therefore likely not perfectly optimized, the efficiency is actually surprisingly good to me. Showing that this training procedure was actually possible spurred a lot of interest in deep learning, which has since performed extremely well on other artificial intelligence tasks, such as speech recognition.
</p>

<p style="padding-left: 10px; padding-right: 10px;">The template for this website has been adopted from Carl Doersch.
</p>

</div>

</body>
</html>
